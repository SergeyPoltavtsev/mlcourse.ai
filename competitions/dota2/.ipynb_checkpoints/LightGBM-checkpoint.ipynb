{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = './data'\n",
    "train_df = pd.read_csv(os.path.join(PATH_TO_DATA,'train_features.csv'), index_col='match_id_hash')\n",
    "target_df = pd.read_csv(os.path.join(PATH_TO_DATA,'train_targets.csv'), index_col='match_id_hash')\n",
    "test_df = pd.read_csv(os.path.join(PATH_TO_DATA, 'test_features.csv'), index_col='match_id_hash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 5\n",
    "folds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.reset_index(drop=True)\n",
    "y = target_df['radiant_win']\n",
    "X_test = test_df.copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {'boost': 'gbdt',\n",
    "          'feature_fraction': 0.05,\n",
    "          'learning_rate': 0.01,\n",
    "          'max_depth': -1,  \n",
    "          'metric':'auc',\n",
    "          'min_data_in_leaf': 50,\n",
    "          'num_leaves': 32,\n",
    "          'num_threads': -1,\n",
    "          'verbosity': 1,\n",
    "          'objective': 'binary'\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-7bcdf27e0f0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     model = lgb.train(lgb_params, \n\u001b[1;32m---> 13\u001b[1;33m                       \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m                       \u001b[0mnum_boost_round\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                       \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "feature_importance = pd.DataFrame()\n",
    "scores = []\n",
    "prediction = np.zeros(len(X_test))\n",
    "\n",
    "for fold_n, (train_index, valid_index) in enumerate(folds.split(X, y)):\n",
    "    X_train, X_valid = X.loc[train_index], X.loc[valid_index]\n",
    "    y_train, y_valid = y[train_index], y[valid_index]\n",
    "    \n",
    "    train_dataset = lgb.Dataset(X_train, label=y_train)\n",
    "    valid_dataset = lgb.Dataset(X_valid, label=y_valid)\n",
    "    \n",
    "    model = lgb.train(lgb_params, \n",
    "                      train_dataset, \n",
    "                      num_boost_round=20000,\n",
    "                      valid_sets = [train_data, valid_data],\n",
    "                      verbose_eval=1000,\n",
    "                      early_stopping_rounds=200)\n",
    "    \n",
    "    y_pred_valid = model.predict(X_valid)\n",
    "    y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "\n",
    "    # scores\n",
    "    scores.append(roc_auc_score(y_valid, y_pred_valid))\n",
    "\n",
    "    # Summing the predictions over 5 models to get average\n",
    "    prediction += y_pred\n",
    "    \n",
    "    # feature importance\n",
    "    fold_importance = pd.DataFrame()\n",
    "    fold_importance[\"feature\"] = X.columns\n",
    "    fold_importance[\"importance\"] = model.feature_importance()\n",
    "    fold_importance[\"fold\"] = fold_n + 1\n",
    "    feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "    \n",
    "\n",
    "    \n",
    "prediction /= n_fold\n",
    "print('CV mean score: {0:.4f}, std: {1:.4f}'.format(np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_data = lgb.Dataset(X_train, y_train)\n",
    "valid_data = lgb.Dataset(X_valid, y_valid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
