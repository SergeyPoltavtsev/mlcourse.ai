{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = './data'\n",
    "train_df = pd.read_csv(os.path.join(PATH_TO_DATA,'train_features.csv'), index_col='match_id_hash')\n",
    "target_df = pd.read_csv(os.path.join(PATH_TO_DATA,'train_targets.csv'), index_col='match_id_hash')\n",
    "test_df = pd.read_csv(os.path.join(PATH_TO_DATA, 'test_features.csv'), index_col='match_id_hash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 5\n",
    "folds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.reset_index(drop=True)\n",
    "y = target_df['radiant_win']\n",
    "X_test = test_df.copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {'boost': 'gbdt',\n",
    "          'feature_fraction': 0.05,\n",
    "          'learning_rate': 0.01,\n",
    "          'max_depth': -1,  \n",
    "          'metric':'auc',\n",
    "          'min_data_in_leaf': 50,\n",
    "          'num_leaves': 32,\n",
    "          'num_threads': -1,\n",
    "          'verbosity': 1,\n",
    "          'objective': 'binary'\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's auc: 0.871492\tvalid_1's auc: 0.801783\n",
      "[2000]\ttraining's auc: 0.9164\tvalid_1's auc: 0.808636\n",
      "[3000]\ttraining's auc: 0.947942\tvalid_1's auc: 0.811622\n",
      "[4000]\ttraining's auc: 0.968687\tvalid_1's auc: 0.812984\n",
      "[5000]\ttraining's auc: 0.981789\tvalid_1's auc: 0.813686\n",
      "[6000]\ttraining's auc: 0.989784\tvalid_1's auc: 0.814289\n",
      "[7000]\ttraining's auc: 0.994476\tvalid_1's auc: 0.814728\n",
      "Early stopping, best iteration is:\n",
      "[7714]\ttraining's auc: 0.996635\tvalid_1's auc: 0.815097\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's auc: 0.873833\tvalid_1's auc: 0.790416\n",
      "[2000]\ttraining's auc: 0.918218\tvalid_1's auc: 0.796412\n",
      "[3000]\ttraining's auc: 0.949392\tvalid_1's auc: 0.799156\n",
      "[4000]\ttraining's auc: 0.969524\tvalid_1's auc: 0.800527\n",
      "[5000]\ttraining's auc: 0.982465\tvalid_1's auc: 0.801479\n",
      "Early stopping, best iteration is:\n",
      "[5569]\ttraining's auc: 0.98725\tvalid_1's auc: 0.801694\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's auc: 0.870779\tvalid_1's auc: 0.803465\n",
      "[2000]\ttraining's auc: 0.915852\tvalid_1's auc: 0.809202\n",
      "[3000]\ttraining's auc: 0.947967\tvalid_1's auc: 0.811985\n",
      "[4000]\ttraining's auc: 0.96877\tvalid_1's auc: 0.813285\n",
      "Early stopping, best iteration is:\n",
      "[4139]\ttraining's auc: 0.970979\tvalid_1's auc: 0.813336\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's auc: 0.870895\tvalid_1's auc: 0.806751\n",
      "[2000]\ttraining's auc: 0.915844\tvalid_1's auc: 0.813039\n",
      "[3000]\ttraining's auc: 0.947777\tvalid_1's auc: 0.815858\n",
      "[4000]\ttraining's auc: 0.968572\tvalid_1's auc: 0.8174\n",
      "[5000]\ttraining's auc: 0.981848\tvalid_1's auc: 0.818407\n",
      "[6000]\ttraining's auc: 0.989928\tvalid_1's auc: 0.819021\n",
      "Early stopping, best iteration is:\n",
      "[6697]\ttraining's auc: 0.993546\tvalid_1's auc: 0.819467\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's auc: 0.870994\tvalid_1's auc: 0.804237\n",
      "[2000]\ttraining's auc: 0.915604\tvalid_1's auc: 0.811135\n",
      "[3000]\ttraining's auc: 0.947267\tvalid_1's auc: 0.81449\n",
      "[4000]\ttraining's auc: 0.967857\tvalid_1's auc: 0.815878\n",
      "Early stopping, best iteration is:\n",
      "[4522]\ttraining's auc: 0.975451\tvalid_1's auc: 0.81629\n",
      "CV mean score: 0.8132, std: 0.0061\n"
     ]
    }
   ],
   "source": [
    "feature_importance = pd.DataFrame()\n",
    "scores = []\n",
    "prediction = np.zeros(len(X_test))\n",
    "\n",
    "for fold_n, (train_index, valid_index) in enumerate(folds.split(X, y)):\n",
    "    X_train, X_valid = X.loc[train_index], X.loc[valid_index]\n",
    "    y_train, y_valid = y[train_index], y[valid_index]\n",
    "    \n",
    "    train_dataset = lgb.Dataset(X_train, label=y_train)\n",
    "    valid_dataset = lgb.Dataset(X_valid, label=y_valid)\n",
    "    \n",
    "    model = lgb.train(lgb_params, \n",
    "                      train_dataset, \n",
    "                      num_boost_round=20000,\n",
    "                      valid_sets = [train_dataset, valid_dataset],\n",
    "                      verbose_eval=1000,\n",
    "                      early_stopping_rounds=200)\n",
    "    \n",
    "    y_pred_valid = model.predict(X_valid)\n",
    "    y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "\n",
    "    # scores\n",
    "    scores.append(roc_auc_score(y_valid, y_pred_valid))\n",
    "\n",
    "    # Summing the predictions over 5 models to get average\n",
    "    prediction += y_pred\n",
    "    \n",
    "    # feature importance\n",
    "    fold_importance = pd.DataFrame()\n",
    "    fold_importance[\"feature\"] = X.columns\n",
    "    fold_importance[\"importance\"] = model.feature_importance()\n",
    "    fold_importance[\"fold\"] = fold_n + 1\n",
    "    feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "    \n",
    "\n",
    "    \n",
    "prediction /= n_fold\n",
    "print('CV mean score: {0:.4f}, std: {1:.4f}'.format(np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_data = lgb.Dataset(X_train, y_train)\n",
    "valid_data = lgb.Dataset(X_valid, y_valid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
